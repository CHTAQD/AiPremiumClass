{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "from torchvision.datasets import  KMNIST;\n",
    "#将图像转为张量\n",
    "from torchvision.transforms.v2 import ToTensor; \n",
    "\n",
    "#数据捆绑 attach\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "LR = 1e-3;\n",
    "\n",
    "#训练的轮次\n",
    "epochs = 20;\n",
    "\n",
    "BATCH_SIZE = 64;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#加载数据集 train true是训练数据 false 是测试数据 设置 transform= ToTensor 返回的数据是一个元组\n",
    "train_data = KMNIST(root=\"./fashion_data\", train=True, download=True, transform=ToTensor())#\n",
    "train_text = KMNIST(root=\"./fashion_data\", train=False, download=True, transform=ToTensor())#\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#shuffle=True 在每个 epoch 开始前，对 train_data 随机打乱。\n",
    "train_dl = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# img, clzz = train_data[0]\n",
    "\n",
    "# plt.imshow(img,cmap='gray');\n",
    "\n",
    "# plt.title(clzz);\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784,64),\n",
    "    nn.Sigmoid(), # 多加一层隐藏层 运算\n",
    "    # nn.Linear(64,100),\n",
    "    # nn.Sigmoid(),\n",
    "    nn.Linear(64,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "lossFn = nn.CrossEntropyLoss();\n",
    "\n",
    "#优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3711185455322266\n",
      "2.3427536487579346\n",
      "2.3770718574523926\n",
      "2.3992807865142822\n",
      "2.3772666454315186\n",
      "2.317934274673462\n",
      "2.3504135608673096\n",
      "2.414647102355957\n",
      "2.3615753650665283\n",
      "2.3549699783325195\n",
      "2.3570926189422607\n",
      "2.2938573360443115\n",
      "2.4290549755096436\n",
      "2.3546743392944336\n",
      "2.3375046253204346\n",
      "2.3656036853790283\n",
      "2.3226537704467773\n",
      "2.3246963024139404\n",
      "2.2895572185516357\n",
      "2.301424264907837\n"
     ]
    }
   ],
   "source": [
    " for item in range(epochs) :\n",
    "    for data,target in train_dl:\n",
    "        #向前运算\n",
    "        output = model(data.reshape(-1,784))\n",
    "\n",
    "        #计算损失\n",
    "        loss = lossFn(output,target)\n",
    "\n",
    "        #反向传播 执行梯度下降 优化神经网络参数 是损失降低 提高模型性能\n",
    "        optimizer.zero_grad() #所有参数梯度清零\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1043\n",
      "Accuracy:10.43 %\n"
     ]
    }
   ],
   "source": [
    "text_dl = DataLoader(train_text,batch_size=BATCH_SIZE);\n",
    "\n",
    "correct = 0;\n",
    "total = 0;\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in text_dl:\n",
    "        output = model(data.reshape(-1,784))\n",
    "        _,predicted = torch.max(output,1);\n",
    "        total += target.size(0)\n",
    "        # print(target.size(0))\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(total,correct)\n",
    "print(f'Accuracy:{correct / total * 100} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1876e-01, -3.4036e-03,  1.2267e-01,  4.7417e-01, -1.3722e-01,\n",
       "          2.2076e-01,  5.1118e-01, -3.4882e-01, -5.5465e-01,  2.1238e-02],\n",
       "        [ 3.1967e-01,  7.1832e-03,  1.5360e-01,  4.4669e-01, -2.1740e-01,\n",
       "          2.1703e-01,  4.9661e-01, -3.4896e-01, -5.5147e-01,  8.4969e-02],\n",
       "        [ 3.0635e-01, -1.0429e-02,  2.0211e-01,  4.6739e-01, -2.0921e-01,\n",
       "          1.6563e-01,  5.3227e-01, -3.7469e-01, -5.6386e-01,  8.2603e-02],\n",
       "        [ 3.3623e-01, -1.5164e-02,  1.7370e-01,  4.7300e-01, -2.2315e-01,\n",
       "          1.7304e-01,  5.1513e-01, -3.5777e-01, -5.3907e-01,  4.7294e-02],\n",
       "        [ 2.9684e-01,  1.7170e-02,  1.8044e-01,  5.0425e-01, -1.9138e-01,\n",
       "          1.7392e-01,  4.8272e-01, -3.9424e-01, -5.0273e-01,  3.9087e-02],\n",
       "        [ 2.8828e-01,  9.7524e-03,  1.5433e-01,  4.2463e-01, -2.2531e-01,\n",
       "          1.8432e-01,  5.0059e-01, -3.1976e-01, -5.4913e-01,  3.0929e-02],\n",
       "        [ 3.2409e-01,  2.8663e-02,  1.6906e-01,  4.8449e-01, -2.0739e-01,\n",
       "          1.6676e-01,  5.3702e-01, -3.8905e-01, -5.5022e-01,  8.0306e-02],\n",
       "        [ 3.7635e-01, -1.9142e-02,  1.3024e-01,  4.7417e-01, -1.8268e-01,\n",
       "          1.9173e-01,  5.3412e-01, -3.6771e-01, -5.4305e-01,  7.4293e-02],\n",
       "        [ 2.9943e-01,  1.0394e-02,  1.6154e-01,  4.8441e-01, -2.0686e-01,\n",
       "          2.0795e-01,  4.9486e-01, -3.5885e-01, -5.7561e-01,  5.5926e-02],\n",
       "        [ 3.3749e-01,  1.3029e-03,  1.5604e-01,  4.8793e-01, -2.2897e-01,\n",
       "          1.7726e-01,  5.2427e-01, -3.4775e-01, -5.3797e-01,  7.8067e-02],\n",
       "        [ 3.1235e-01, -2.1342e-02,  1.1176e-01,  4.8405e-01, -1.5475e-01,\n",
       "          2.2053e-01,  5.2695e-01, -3.7481e-01, -5.4085e-01,  3.6220e-02],\n",
       "        [ 3.0686e-01,  4.4211e-02,  1.2066e-01,  4.5870e-01, -2.2233e-01,\n",
       "          1.7142e-01,  5.5070e-01, -3.2312e-01, -5.2682e-01,  1.1467e-01],\n",
       "        [ 3.1223e-01,  2.3511e-03,  1.9073e-01,  4.6604e-01, -1.3662e-01,\n",
       "          1.3620e-01,  5.5024e-01, -3.8096e-01, -5.5285e-01,  2.7555e-02],\n",
       "        [ 2.9221e-01,  4.1244e-02,  1.5321e-01,  3.9661e-01, -2.1259e-01,\n",
       "          1.5191e-01,  5.7556e-01, -3.4452e-01, -5.1901e-01,  7.7886e-02],\n",
       "        [ 2.9350e-01,  4.6052e-04,  1.4036e-01,  4.4197e-01, -2.0341e-01,\n",
       "          1.7808e-01,  5.1570e-01, -3.4964e-01, -5.2622e-01,  9.6833e-02],\n",
       "        [ 3.2836e-01,  4.3004e-02,  1.7224e-01,  4.6191e-01, -2.0993e-01,\n",
       "          1.1913e-01,  5.2374e-01, -3.1496e-01, -5.1002e-01,  9.6919e-02]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
